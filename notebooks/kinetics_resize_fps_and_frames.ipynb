{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'NETWORK': {'BACKBONE': 'res18',\n",
       "  'BACKBONE_LOAD_PRETRAINED': True,\n",
       "  'TEMPORAL_MLP_DIMS': 512,\n",
       "  'TEMPORAL_MLP_ACTIVATION': 'LeakyReLU',\n",
       "  'TRANSFORMER_DIMS': 512,\n",
       "  'TRANSFORMER_HEADS': 8,\n",
       "  'TRANSFORMER_ENCODER_CNT': 8,\n",
       "  'TRANSFORMER_DROPOUT': 0.1,\n",
       "  'TRANSFORMER_FEEDFORWARD_DIMS': 2048,\n",
       "  'POSITIONAL_DROPOUT': 0.1,\n",
       "  'NUM_CLASSES': 700}}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from easydict import EasyDict as edict\n",
    "from PIL import Image\n",
    "import torch, torchvision\n",
    "from torchvision.datasets.video_utils import VideoClips\n",
    "import os, json\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from time import time\n",
    "import pickle as pkl\n",
    "from collections import Counter as C\n",
    "\n",
    "_C = edict()\n",
    "_C.NETWORK = edict()\n",
    "_C.NETWORK.BACKBONE = \"res18\"\n",
    "_C.NETWORK.BACKBONE_LOAD_PRETRAINED = True\n",
    "\n",
    "_C.NETWORK.TEMPORAL_MLP_DIMS = 512\n",
    "_C.NETWORK.TEMPORAL_MLP_ACTIVATION = \"LeakyReLU\"\n",
    "\n",
    "_C.NETWORK.TRANSFORMER_DIMS = 512\n",
    "_C.NETWORK.TRANSFORMER_HEADS = 8\n",
    "_C.NETWORK.TRANSFORMER_ENCODER_CNT = 8\n",
    "_C.NETWORK.TRANSFORMER_DROPOUT = 0.1\n",
    "_C.NETWORK.TRANSFORMER_FEEDFORWARD_DIMS = 2048\n",
    "\n",
    "_C.NETWORK.POSITIONAL_DROPOUT = 0.1\n",
    "_C.NETWORK.NUM_CLASSES = 700\n",
    "_C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "basepath = '/data/datasets/kinetics700_2020/'\n",
    "train_dataset = json.load(open(basepath + \"labels/train.json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('-7N2pxxB2f4',\n",
       " {'annotations': {'label': 'frying vegetables', 'segment': [267.0, 277.0]},\n",
       "  'duration': 10.0,\n",
       "  'subset': 'train',\n",
       "  'url': 'https://www.youtube.com/watch?v=-7N2pxxB2f4',\n",
       "  'nb_frames': '250',\n",
       "  'hw': [1080, 1920],\n",
       "  'true_duration': '10.000000'})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(train_dataset.items())[990]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "def bench(cmd,iter):\n",
    "    tic = time()\n",
    "    for i in range(iter):\n",
    "        cmd()\n",
    "    print(time() - tic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class load_and_dump(Dataset):\n",
    "    def __init__(self, dataset, video_folder, save_folder):\n",
    "        super(load_and_dump, self).__init__()\n",
    "        assert video_folder[-1] == '/'\n",
    "        assert save_folder[-1] == '/'\n",
    "\n",
    "        self.dataset = list(dataset.items())\n",
    "        self.video_path = video_folder\n",
    "        self.save_path = save_folder\n",
    "        assert self.video_path != self.save_path\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        k, v = self.dataset[idx]\n",
    "\n",
    "        vid_path = self.video_path + k + '.mp4'\n",
    "        save_path = self.save_path + k + '.mp4' \n",
    "\n",
    "        # Remove Audio, Subtitles ; Resize Video to 224X224 and 10 fps\n",
    "        os.system(\"ffmpeg -i \" + vid_path + ' -vf \"fps=10,scale=224:224\" -an -sn ' + save_path)\n",
    "        \n",
    "        return k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 / 523099\n",
      "500 / 523099\n",
      "1000 / 523099\n",
      "1500 / 523099\n",
      "2000 / 523099\n",
      "2500 / 523099\n",
      "3000 / 523099\n",
      "3500 / 523099\n",
      "4000 / 523099\n",
      "4500 / 523099\n",
      "5000 / 523099\n",
      "5500 / 523099\n",
      "6000 / 523099\n",
      "6500 / 523099\n",
      "7000 / 523099\n",
      "7500 / 523099\n",
      "8000 / 523099\n",
      "8500 / 523099\n",
      "9000 / 523099\n",
      "9500 / 523099\n",
      "10000 / 523099\n",
      "10500 / 523099\n",
      "11000 / 523099\n",
      "11500 / 523099\n",
      "12000 / 523099\n",
      "12500 / 523099\n",
      "13000 / 523099\n",
      "13500 / 523099\n",
      "14000 / 523099\n",
      "14500 / 523099\n",
      "15000 / 523099\n",
      "15500 / 523099\n",
      "16000 / 523099\n",
      "16500 / 523099\n",
      "17000 / 523099\n",
      "17500 / 523099\n",
      "18000 / 523099\n",
      "18500 / 523099\n",
      "19000 / 523099\n",
      "19500 / 523099\n",
      "20000 / 523099\n",
      "20500 / 523099\n",
      "21000 / 523099\n",
      "21500 / 523099\n",
      "22000 / 523099\n",
      "22500 / 523099\n",
      "23000 / 523099\n",
      "23500 / 523099\n",
      "24000 / 523099\n",
      "24500 / 523099\n",
      "25000 / 523099\n",
      "25500 / 523099\n",
      "26000 / 523099\n",
      "26500 / 523099\n",
      "27000 / 523099\n",
      "27500 / 523099\n",
      "28000 / 523099\n",
      "28500 / 523099\n",
      "29000 / 523099\n",
      "29500 / 523099\n",
      "30000 / 523099\n",
      "30500 / 523099\n",
      "31000 / 523099\n",
      "31500 / 523099\n",
      "32000 / 523099\n",
      "32500 / 523099\n",
      "33000 / 523099\n",
      "33500 / 523099\n",
      "34000 / 523099\n",
      "34500 / 523099\n",
      "35000 / 523099\n",
      "35500 / 523099\n"
     ]
    }
   ],
   "source": [
    "collate = lambda x: x\n",
    "batch_size = 60\n",
    "dataset = DataLoader(load_and_dump(dict(list(train_dataset.items())),\n",
    "                                    basepath + 'train/',\n",
    "                                    basepath + 'train_cache/',\n",
    "                                ),\n",
    "                     batch_size=batch_size,\n",
    "                     num_workers=batch_size,\n",
    "                     collate_fn=collate\n",
    "                    )\n",
    "probes = []\n",
    "for i, batch in enumerate(dataset):\n",
    "    if i % 10 == 0:\n",
    "        print(i*50,'/', len(train_dataset))\n",
    "    probes.append(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(probes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probes[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tsat",
   "language": "python",
   "name": "tsat"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
