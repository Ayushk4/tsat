{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'NETWORK': {'BACKBONE': 'res18',\n",
       "  'BACKBONE_LOAD_PRETRAINED': True,\n",
       "  'TEMPORAL_MLP_DIMS': 512,\n",
       "  'TEMPORAL_MLP_ACTIVATION': 'LeakyReLU',\n",
       "  'TRANSFORMER_DIMS': 512,\n",
       "  'TRANSFORMER_HEADS': 8,\n",
       "  'TRANSFORMER_ENCODER_CNT': 8,\n",
       "  'TRANSFORMER_DROPOUT': 0.1,\n",
       "  'TRANSFORMER_FEEDFORWARD_DIMS': 2048,\n",
       "  'POSITIONAL_DROPOUT': 0.1,\n",
       "  'NUM_CLASSES': 700}}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from easydict import EasyDict as edict\n",
    "from PIL import Image\n",
    "import torch, torchvision\n",
    "from torchvision.datasets.video_utils import VideoClips\n",
    "import os, json\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from time import time\n",
    "import pickle as pkl\n",
    "from collections import Counter as C\n",
    "\n",
    "_C = edict()\n",
    "_C.NETWORK = edict()\n",
    "_C.NETWORK.BACKBONE = \"res18\"\n",
    "_C.NETWORK.BACKBONE_LOAD_PRETRAINED = True\n",
    "\n",
    "_C.NETWORK.TEMPORAL_MLP_DIMS = 512\n",
    "_C.NETWORK.TEMPORAL_MLP_ACTIVATION = \"LeakyReLU\"\n",
    "\n",
    "_C.NETWORK.TRANSFORMER_DIMS = 512\n",
    "_C.NETWORK.TRANSFORMER_HEADS = 8\n",
    "_C.NETWORK.TRANSFORMER_ENCODER_CNT = 8\n",
    "_C.NETWORK.TRANSFORMER_DROPOUT = 0.1\n",
    "_C.NETWORK.TRANSFORMER_FEEDFORWARD_DIMS = 2048\n",
    "\n",
    "_C.NETWORK.POSITIONAL_DROPOUT = 0.1\n",
    "_C.NETWORK.NUM_CLASSES = 700\n",
    "_C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "basepath = '/data/datasets/kinetics700_2020/'\n",
    "val_dataset = json.load(open(basepath + \"full/val.json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('47tFTCZxPNc',\n",
       " {'annotations': {'label': ['karaoke', 596], 'segment': [18.0, 28.0]},\n",
       "  'duration': 10.0,\n",
       "  'subset': 'validate',\n",
       "  'url': 'https://www.youtube.com/watch?v=47tFTCZxPNc',\n",
       "  'nb_frames': '150',\n",
       "  'hw': [144, 192],\n",
       "  'true_duration': '10.000000'})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(val_dataset.items())[990]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "def bench(cmd,iter):\n",
    "    tic = time()\n",
    "    for i in range(iter):\n",
    "        cmd()\n",
    "    print(time() - tic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class load_and_dump(Dataset):\n",
    "    def __init__(self, dataset, video_folder, save_folder):\n",
    "        super(load_and_dump, self).__init__()\n",
    "        assert video_folder[-1] == '/'\n",
    "        assert save_folder[-1] == '/'\n",
    "\n",
    "        self.dataset = list(dataset.items())\n",
    "        self.video_path = video_folder\n",
    "        self.save_path = save_folder\n",
    "        assert self.video_path != self.save_path\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        k, v = self.dataset[idx]\n",
    "\n",
    "        vid_path = self.video_path + k + '.mp4'\n",
    "        save_path = self.save_path + k + '.mp4' \n",
    "\n",
    "        # Remove Audio, Subtitles ; Resize Video to 224X224 and 10 fps\n",
    "        #os.system(\"ffmpeg -i \" + vid_path + ' -vf \"fps=10,scale=224:224\" -an -sn ' + save_path)\n",
    "        os.system(\"ffmpeg -i \" + vid_path + ' -vf \"fps=10,scale=\\'if(gt(a,1),-2,256)\\':\\'if(gt(a,1),256,-2)\\'\" -an -sn ' + save_path)\n",
    "        #ffmpeg -i \"%1\" -vf \"scale='if(gt(a,1),-2,256)':'if(gt(a,1),256,-2)'\" -qscale:v 2 frames/out-%03d.jpg\n",
    "\n",
    "        \n",
    "        return k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "collate = lambda x: x\n",
    "batch_size = 60\n",
    "assert os.path.exists(basepath + 'val_cache_short_fixed/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 / 32732\n",
      "600 / 32732\n",
      "1200 / 32732\n",
      "1800 / 32732\n",
      "2400 / 32732\n",
      "3000 / 32732\n",
      "3600 / 32732\n",
      "4200 / 32732\n",
      "4800 / 32732\n",
      "5400 / 32732\n",
      "6000 / 32732\n",
      "6600 / 32732\n",
      "7200 / 32732\n",
      "7800 / 32732\n",
      "8400 / 32732\n",
      "9000 / 32732\n",
      "9600 / 32732\n",
      "10200 / 32732\n",
      "10800 / 32732\n",
      "11400 / 32732\n",
      "12000 / 32732\n",
      "12600 / 32732\n",
      "13200 / 32732\n",
      "13800 / 32732\n",
      "14400 / 32732\n",
      "15000 / 32732\n",
      "15600 / 32732\n",
      "16200 / 32732\n",
      "16800 / 32732\n",
      "17400 / 32732\n",
      "18000 / 32732\n",
      "18600 / 32732\n",
      "19200 / 32732\n",
      "19800 / 32732\n",
      "20400 / 32732\n",
      "21000 / 32732\n",
      "21600 / 32732\n",
      "22200 / 32732\n",
      "22800 / 32732\n",
      "23400 / 32732\n",
      "24000 / 32732\n",
      "24600 / 32732\n",
      "25200 / 32732\n",
      "25800 / 32732\n",
      "26400 / 32732\n",
      "27000 / 32732\n",
      "27600 / 32732\n",
      "28200 / 32732\n",
      "28800 / 32732\n",
      "29400 / 32732\n",
      "30000 / 32732\n",
      "30600 / 32732\n",
      "31200 / 32732\n",
      "31800 / 32732\n",
      "32400 / 32732\n"
     ]
    }
   ],
   "source": [
    "dataset = DataLoader(load_and_dump(dict(list(val_dataset.items())),\n",
    "                                    basepath + 'val/',\n",
    "                                    basepath + 'val_cache_short_fixed/',\n",
    "                                ),\n",
    "                     batch_size=batch_size,\n",
    "                     num_workers=batch_size,\n",
    "                     collate_fn=collate\n",
    "                    )\n",
    "probes = []\n",
    "for i, batch in enumerate(dataset):\n",
    "    if i % 10 == 0:\n",
    "        print(i*batch_size,'/', len(val_dataset))\n",
    "    probes.append(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(probes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probes[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_json_file = json.load(open('/data/datasets/kinetics700_2020/full/val.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('---QUuC4vJs',\n",
       " {'annotations': {'label': ['testifying', 104], 'segment': [84.0, 94.0]},\n",
       "  'duration': 10.0,\n",
       "  'subset': 'validate',\n",
       "  'url': 'https://www.youtube.com/watch?v=---QUuC4vJs',\n",
       "  'nb_frames': '300',\n",
       "  'hw': [240, 320],\n",
       "  'true_duration': '10.009972'})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(val_json_file.items())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert json annotations to CSV files as required in SlowFast code\n",
    "\n",
    "def convert_json_to_csv_annotations(mode='train'):\n",
    "    basepath = '/data/datasets/kinetics700_2020/'\n",
    "    # create a csv file\n",
    "    csv_file = open(os.path.join(basepath, f'full/{mode}.csv'), 'w+')\n",
    "    \n",
    "    # load json file\n",
    "    json_file = json.load(open(os.path.join(basepath, f'full/{mode}.json')))\n",
    "    \n",
    "    print(f\"length of the {mode} annotations file is : {len(json_file)}\")\n",
    "                          \n",
    "    # list\n",
    "    lines = []\n",
    "    \n",
    "    for k, v in json_file.items():\n",
    "        # create path\n",
    "        path = os.path.join(basepath, f'{mode}_cache_short_fixed/{k}.mp4')\n",
    "        lines.append(','.join([path, str(v['annotations']['label'][1])]))\n",
    "        \n",
    "    csv_file.write('\\n'.join(lines))\n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of the train annotations file is : 523098\n"
     ]
    }
   ],
   "source": [
    "convert_json_to_csv_annotations('train')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tsat",
   "language": "python",
   "name": "tsat"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
